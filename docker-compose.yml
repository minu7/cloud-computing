version: '2'

services:
  zookeeper:
    image: 'docker.io/bitnami/zookeeper:3-debian-10'
    ports:
      - '2181:2181'
    # volumes:
    #   - 'zookeeper_data:/bitnami'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: 'docker.io/bitnami/kafka:2-debian-10'
    ports:
      - '9092:9092'
    # volumes:
    #   - 'kafka_data:/bitnami'
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on:
      - zookeeper


  producer:
    container_name: timeseries-producer
    image: 'node:12'
    volumes:
      - ./timeseries-producer:/home/task
    working_dir: /home/task
    command: node index.js
    depends_on:
      - kafka


  spark:
    build: ./spark 
    # image: docker.io/bitnami/spark:3-debian-10
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'
    depends_on:
      - 'kafka'
    user: root
    volumes:
      - ./spark:/opt/bitnami/spark/candlestick
    command: 'bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0 candlestick/main.py kafka:9092 bitcoin'
 
  # spark-worker-1:
  #   build: ./spark-regression
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark:7077
  #     - SPARK_WORKER_MEMORY=1G
  #     - SPARK_WORKER_CORES=1
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  # spark-worker-2:
  #   build: ./spark-regression
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark:7077
  #     - SPARK_WORKER_MEMORY=1G
  #     - SPARK_WORKER_CORES=1
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no



  consumer:
    container_name: consumer-candlesticks
    image: 'node:12'
    volumes:
      - ./consumer:/home/task
    working_dir: /home/task
    command: node index.js
    restart: on-failure
    depends_on:
      - kafka

  mongo:
    image: mongo:4.2
    # restart: always
    ports:
      - "27017:27017"
    # volumes:
    #  - task:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: password


  mongo-express:
    image: mongo-express
    # restart: always
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: password

  frontend:
    container_name: frontend
    image: 'node:12'
    ports:
      - 80:80
    volumes:
      - ./frontend:/home/task
    working_dir: /home/task
    command: node index.js
    restart: on-failure
    depends_on:
      - kafka

  backend:
    container_name: backend
    build: ./backend
    volumes:
      - ./backend:/home/task
    working_dir: /home/task
    command: python -u api/main.py
    restart: on-failure
    environment:
      - PYTHONUNBUFFERED=0
    depends_on:
      - kafka
      - mongo



# volumes:
#   zookeeper_data:
#     driver: local
#   kafka_data:
#     driver: local
